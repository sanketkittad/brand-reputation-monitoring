{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283e2492-d372-4fe7-ba1c-60e010eb42ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from better_profanity import profanity\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e75aab7-7e6f-430a-b9d4-6a40f743b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(data_frame):\n",
    "        data_frame_list=data_frame['tweet_text_element'].to_list()\n",
    "        \n",
    "        cleaned_data_frame=[clean(tweet) for tweet in data_frame_list]\n",
    "        \n",
    "        data_frame_objects=[TextBlob(tweet) for tweet in cleaned_data_frame]\n",
    "\n",
    "        sentiment_data_frame = [[tweet.sentiment.polarity, str(tweet)] for tweet in data_frame_objects]\n",
    "      \n",
    "        sentiment_df_data_frame = pd.DataFrame(sentiment_data_frame, columns=[\"polarity\", \"tweet\"])\n",
    "      \n",
    "        conditions =[(sentiment_df_data_frame['polarity'] >0.2),(sentiment_df_data_frame['polarity'] <0.1)]\n",
    "        choices = ['Positive', 'Negative']\n",
    "        sentiment_df_data_frame['sentiment'] = np.select(conditions, choices)\n",
    "        data_frame_pos=0\n",
    "        if \"Positive\" in sentiment_df_data_frame['sentiment'].values:\n",
    "            data_frame_pos=sentiment_df_data_frame['sentiment'].value_counts()['Positive']\n",
    "        data_frame_neg=0\n",
    "        if \"Negative\" in sentiment_df_data_frame['sentiment'].values:\n",
    "            data_frame_neg=sentiment_df_data_frame['sentiment'].value_counts()['Negative']\n",
    "       \n",
    "        data_frame_data={\n",
    "            'sentiment':['Positive',\n",
    "            'Negative'],'count':[data_frame_pos,data_frame_neg]\n",
    "        }\n",
    "        data_frame_data=pd.DataFrame(data_frame_data)    \n",
    "        return data_frame_data\n",
    "\n",
    "def clean(tweet):\n",
    "    if(type(tweet)==float):\n",
    "        return \"\"\n",
    "    r=tweet.lower()\n",
    "    r=profanity.censor(r)\n",
    "    r = re.sub(\"\", \"\", r) #This is to avoid removing contractions in english\n",
    "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r)\n",
    "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r)\n",
    "    r = re.sub(r'http\\S+', '', r)\n",
    "    r = re.sub('[()!?]', ' ', r)\n",
    "    r = re.sub('\\[.*?\\]',' ', r)\n",
    "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
    "    r = r.split()\n",
    "    stopwords = [\"for\", \"on\", \"an\", \"a\", \"of\", \"and\", \"in\", \"the\", \"to\", \"from\"]\n",
    "    r = [w for w in r if not w in stopwords]\n",
    "    r = \" \".join(word for word in r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80dc45ac-02f6-4a90-b436-3b490b11efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalized(brand,b_dir):\n",
    "    b_df=pd.DataFrame(columns=[\"positive\",\"negative\"])\n",
    "    for i in b_dir:\n",
    "        if i.endswith(\".csv\"):\n",
    "            data=pd.read_csv(brand+\"/\"+i)\n",
    "        else:\n",
    "            continue\n",
    "        sentiments=getSentiment(data)\n",
    "        name=i\n",
    "        curr_df=name.replace(\".csv\",\"\")\n",
    "        pos=sentiments.iloc[0]['count']\n",
    "        neg=sentiments.iloc[1]['count']\n",
    "        \n",
    "        b_df.loc[len(b_df.index)] =[pos,neg]\n",
    "    scaler=MinMaxScaler(feature_range=(0,1),copy=False)\n",
    "    b_df=scaler.fit_transform(b_df)\n",
    "    print(b_df)\n",
    "    return b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7c58f5c-5f7b-4b00-bc82-a6dc561fa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.22105263]\n",
      " [0.83333333 0.21052632]\n",
      " [0.5        0.07368421]\n",
      " [0.2962963  0.17894737]\n",
      " [0.09259259 0.16842105]\n",
      " [1.         1.        ]\n",
      " [0.2037037  0.17894737]\n",
      " [0.         0.11578947]\n",
      " [0.64814815 0.10526316]\n",
      " [0.96296296 0.6       ]\n",
      " [0.18518519 0.17894737]\n",
      " [0.46296296 0.15789474]\n",
      " [0.31481481 0.14736842]\n",
      " [0.94444444 0.96842105]\n",
      " [0.12962963 0.13684211]\n",
      " [0.14814815 0.38947368]\n",
      " [0.38888889 0.10526316]\n",
      " [0.7962963  0.92631579]\n",
      " [0.2037037  0.21052632]\n",
      " [0.46296296 0.        ]\n",
      " [0.5        0.14736842]\n",
      " [0.11111111 0.54736842]\n",
      " [0.2962963  0.15789474]\n",
      " [0.09259259 0.12631579]\n",
      " [0.24074074 0.09473684]\n",
      " [0.22222222 0.16842105]\n",
      " [0.33333333 0.12631579]\n",
      " [0.31481481 0.18947368]\n",
      " [0.2962963  0.02105263]\n",
      " [0.22222222 0.2       ]\n",
      " [0.16666667 0.22105263]\n",
      " [0.59259259 0.08421053]\n",
      " [0.18518519 0.10526316]\n",
      " [0.16666667 0.26315789]\n",
      " [0.33333333 0.11578947]\n",
      " [0.16666667 0.29473684]\n",
      " [0.18518519 0.09473684]\n",
      " [0.         0.23157895]\n",
      " [0.44444444 0.21052632]\n",
      " [0.27777778 0.49473684]\n",
      " [0.5        0.14736842]\n",
      " [0.44444444 0.09473684]\n",
      " [0.09259259 0.2       ]\n",
      " [0.16666667 0.13684211]\n",
      " [0.11111111 0.02105263]\n",
      " [0.44444444 0.24210526]\n",
      " [0.11111111 0.22105263]\n",
      " [0.         0.32631579]\n",
      " [0.24074074 0.28421053]\n",
      " [0.35185185 0.03157895]\n",
      " [0.57407407 0.10526316]]\n",
      "[[0.28395062 0.12056738]\n",
      " [0.38271605 0.26950355]\n",
      " [0.24691358 0.15602837]\n",
      " [0.24691358 0.16312057]\n",
      " [0.12345679 0.17021277]\n",
      " [0.74074074 0.92907801]\n",
      " [0.37037037 0.07801418]\n",
      " [0.25925926 0.09219858]\n",
      " [0.22222222 0.15602837]\n",
      " [1.         1.        ]\n",
      " [0.13580247 0.15602837]\n",
      " [0.22222222 0.14893617]\n",
      " [0.18518519 0.18439716]\n",
      " [0.24691358 0.        ]\n",
      " [0.11111111 0.09929078]\n",
      " [0.0617284  0.06382979]\n",
      " [0.0617284  0.29787234]\n",
      " [0.18518519 0.75886525]\n",
      " [0.18518519 0.14184397]\n",
      " [0.18518519 0.11347518]\n",
      " [0.         0.06382979]\n",
      " [0.65432099 0.9929078 ]\n",
      " [0.18518519 0.07801418]\n",
      " [0.16049383 0.14184397]\n",
      " [0.08641975 0.15602837]\n",
      " [0.65432099 0.40425532]\n",
      " [0.20987654 0.24822695]\n",
      " [0.07407407 0.07092199]\n",
      " [0.14814815 0.09929078]\n",
      " [0.         0.23404255]\n",
      " [0.08641975 0.26241135]\n",
      " [0.09876543 0.22695035]\n",
      " [0.07407407 0.17021277]\n",
      " [0.25925926 0.07801418]\n",
      " [0.0617284  0.11347518]\n",
      " [0.17283951 0.09929078]\n",
      " [0.17283951 0.12056738]\n",
      " [0.         0.24822695]\n",
      " [0.16049383 0.13475177]\n",
      " [0.         0.10638298]\n",
      " [0.13580247 0.11347518]\n",
      " [0.24691358 0.06382979]\n",
      " [0.12345679 0.14184397]\n",
      " [0.13580247 0.09219858]\n",
      " [0.35802469 0.09219858]\n",
      " [0.22222222 0.07801418]\n",
      " [0.20987654 0.10638298]\n",
      " [0.28395062 0.25531915]\n",
      " [0.25925926 0.21985816]\n",
      " [0.18518519 0.11347518]\n",
      " [0.11111111 0.07092199]]\n"
     ]
    }
   ],
   "source": [
    "b1_dir=os.listdir(\"Samsung\")\n",
    "b2_dir=os.listdir(\"Apple\")\n",
    "b1_df=getNormalized(\"Samsung\",b1_dir)\n",
    "b2_df=getNormalized(\"Apple\",b2_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "57f0c6d6-e0ad-42d8-aebb-c3f02954b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=128,input_shape=(2,4)))\n",
    "model.add(Dense(units=64))\n",
    "model.add(Dense(units=32))\n",
    "model.add(Dense(units=16))\n",
    "model.add(Dense(units=1, activation='sigmoid')) \n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "eb017feb-d43e-438a-a2b8-2e986c62e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_df=pd.DataFrame(b1_df,columns=[\"brand_a_pos\",\"brand_a_neg\"])\n",
    "b2_df=pd.DataFrame(b2_df,columns=[\"brand_b_pos\",\"brand_b_neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d40f65a-e75a-48ec-afeb-ff87623696bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_a_pos</th>\n",
       "      <th>brand_a_neg</th>\n",
       "      <th>brand_b_pos</th>\n",
       "      <th>brand_b_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.120567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.269504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.156028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.163121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.929078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.078014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.092199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.156028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.156028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.184397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.758865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.141844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.113475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.992908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.078014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.141844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.156028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.404255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.248227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.070922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.262411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.226950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.078014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.113475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.120567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.134752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.113475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.094737</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.141844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.092199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.092199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.078014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.283951</td>\n",
       "      <td>0.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.240741</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.219858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.113475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.070922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand_a_pos  brand_a_neg  brand_b_pos  brand_b_neg\n",
       "0      0.333333     0.221053     0.283951     0.120567\n",
       "1      0.833333     0.210526     0.382716     0.269504\n",
       "2      0.500000     0.073684     0.246914     0.156028\n",
       "3      0.296296     0.178947     0.246914     0.163121\n",
       "4      0.092593     0.168421     0.123457     0.170213\n",
       "5      1.000000     1.000000     0.740741     0.929078\n",
       "6      0.203704     0.178947     0.370370     0.078014\n",
       "7      0.000000     0.115789     0.259259     0.092199\n",
       "8      0.648148     0.105263     0.222222     0.156028\n",
       "9      0.962963     0.600000     1.000000     1.000000\n",
       "10     0.185185     0.178947     0.135802     0.156028\n",
       "11     0.462963     0.157895     0.222222     0.148936\n",
       "12     0.314815     0.147368     0.185185     0.184397\n",
       "13     0.944444     0.968421     0.246914     0.000000\n",
       "14     0.129630     0.136842     0.111111     0.099291\n",
       "15     0.148148     0.389474     0.061728     0.063830\n",
       "16     0.388889     0.105263     0.061728     0.297872\n",
       "17     0.796296     0.926316     0.185185     0.758865\n",
       "18     0.203704     0.210526     0.185185     0.141844\n",
       "19     0.462963     0.000000     0.185185     0.113475\n",
       "20     0.500000     0.147368     0.000000     0.063830\n",
       "21     0.111111     0.547368     0.654321     0.992908\n",
       "22     0.296296     0.157895     0.185185     0.078014\n",
       "23     0.092593     0.126316     0.160494     0.141844\n",
       "24     0.240741     0.094737     0.086420     0.156028\n",
       "25     0.222222     0.168421     0.654321     0.404255\n",
       "26     0.333333     0.126316     0.209877     0.248227\n",
       "27     0.314815     0.189474     0.074074     0.070922\n",
       "28     0.296296     0.021053     0.148148     0.099291\n",
       "29     0.222222     0.200000     0.000000     0.234043\n",
       "30     0.166667     0.221053     0.086420     0.262411\n",
       "31     0.592593     0.084211     0.098765     0.226950\n",
       "32     0.185185     0.105263     0.074074     0.170213\n",
       "33     0.166667     0.263158     0.259259     0.078014\n",
       "34     0.333333     0.115789     0.061728     0.113475\n",
       "35     0.166667     0.294737     0.172840     0.099291\n",
       "36     0.185185     0.094737     0.172840     0.120567\n",
       "37     0.000000     0.231579     0.000000     0.248227\n",
       "38     0.444444     0.210526     0.160494     0.134752\n",
       "39     0.277778     0.494737     0.000000     0.106383\n",
       "40     0.500000     0.147368     0.135802     0.113475\n",
       "41     0.444444     0.094737     0.246914     0.063830\n",
       "42     0.092593     0.200000     0.123457     0.141844\n",
       "43     0.166667     0.136842     0.135802     0.092199\n",
       "44     0.111111     0.021053     0.358025     0.092199\n",
       "45     0.444444     0.242105     0.222222     0.078014\n",
       "46     0.111111     0.221053     0.209877     0.106383\n",
       "47     0.000000     0.326316     0.283951     0.255319\n",
       "48     0.240741     0.284211     0.259259     0.219858\n",
       "49     0.351852     0.031579     0.185185     0.113475\n",
       "50     0.574074     0.105263     0.111111     0.070922"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.concat([b1_df, b2_df], axis=1)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "aa466c89-c941-4ded-810f-3ba3bdf5b875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.22105263, 0.28395062, 0.12056738],\n",
       "       [0.83333333, 0.21052632, 0.38271605, 0.26950355],\n",
       "       [0.5       , 0.07368421, 0.24691358, 0.15602837],\n",
       "       [0.2962963 , 0.17894737, 0.24691358, 0.16312057],\n",
       "       [0.09259259, 0.16842105, 0.12345679, 0.17021277],\n",
       "       [1.        , 1.        , 0.74074074, 0.92907801],\n",
       "       [0.2037037 , 0.17894737, 0.37037037, 0.07801418],\n",
       "       [0.        , 0.11578947, 0.25925926, 0.09219858],\n",
       "       [0.64814815, 0.10526316, 0.22222222, 0.15602837],\n",
       "       [0.96296296, 0.6       , 1.        , 1.        ],\n",
       "       [0.18518519, 0.17894737, 0.13580247, 0.15602837],\n",
       "       [0.46296296, 0.15789474, 0.22222222, 0.14893617],\n",
       "       [0.31481481, 0.14736842, 0.18518519, 0.18439716],\n",
       "       [0.94444444, 0.96842105, 0.24691358, 0.        ],\n",
       "       [0.12962963, 0.13684211, 0.11111111, 0.09929078],\n",
       "       [0.14814815, 0.38947368, 0.0617284 , 0.06382979],\n",
       "       [0.38888889, 0.10526316, 0.0617284 , 0.29787234],\n",
       "       [0.7962963 , 0.92631579, 0.18518519, 0.75886525],\n",
       "       [0.2037037 , 0.21052632, 0.18518519, 0.14184397],\n",
       "       [0.46296296, 0.        , 0.18518519, 0.11347518],\n",
       "       [0.5       , 0.14736842, 0.        , 0.06382979],\n",
       "       [0.11111111, 0.54736842, 0.65432099, 0.9929078 ],\n",
       "       [0.2962963 , 0.15789474, 0.18518519, 0.07801418],\n",
       "       [0.09259259, 0.12631579, 0.16049383, 0.14184397],\n",
       "       [0.24074074, 0.09473684, 0.08641975, 0.15602837],\n",
       "       [0.22222222, 0.16842105, 0.65432099, 0.40425532],\n",
       "       [0.33333333, 0.12631579, 0.20987654, 0.24822695],\n",
       "       [0.31481481, 0.18947368, 0.07407407, 0.07092199],\n",
       "       [0.2962963 , 0.02105263, 0.14814815, 0.09929078],\n",
       "       [0.22222222, 0.2       , 0.        , 0.23404255],\n",
       "       [0.16666667, 0.22105263, 0.08641975, 0.26241135],\n",
       "       [0.59259259, 0.08421053, 0.09876543, 0.22695035],\n",
       "       [0.18518519, 0.10526316, 0.07407407, 0.17021277],\n",
       "       [0.16666667, 0.26315789, 0.25925926, 0.07801418],\n",
       "       [0.33333333, 0.11578947, 0.0617284 , 0.11347518],\n",
       "       [0.16666667, 0.29473684, 0.17283951, 0.09929078],\n",
       "       [0.18518519, 0.09473684, 0.17283951, 0.12056738],\n",
       "       [0.        , 0.23157895, 0.        , 0.24822695],\n",
       "       [0.44444444, 0.21052632, 0.16049383, 0.13475177],\n",
       "       [0.27777778, 0.49473684, 0.        , 0.10638298],\n",
       "       [0.5       , 0.14736842, 0.13580247, 0.11347518],\n",
       "       [0.44444444, 0.09473684, 0.24691358, 0.06382979],\n",
       "       [0.09259259, 0.2       , 0.12345679, 0.14184397],\n",
       "       [0.16666667, 0.13684211, 0.13580247, 0.09219858],\n",
       "       [0.11111111, 0.02105263, 0.35802469, 0.09219858],\n",
       "       [0.44444444, 0.24210526, 0.22222222, 0.07801418],\n",
       "       [0.11111111, 0.22105263, 0.20987654, 0.10638298],\n",
       "       [0.        , 0.32631579, 0.28395062, 0.25531915],\n",
       "       [0.24074074, 0.28421053, 0.25925926, 0.21985816],\n",
       "       [0.35185185, 0.03157895, 0.18518519, 0.11347518],\n",
       "       [0.57407407, 0.10526316, 0.11111111, 0.07092199]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=df_merged[\"brand_a_pos\"]\n",
    "df_merged=df_merged.to_numpy()\n",
    "target=target.to_numpy()\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "11b4292d-8b5a-4c03-9e17-e126ef335505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333],\n",
       "       [0.83333333],\n",
       "       [0.5       ],\n",
       "       [0.2962963 ],\n",
       "       [0.09259259],\n",
       "       [1.        ],\n",
       "       [0.2037037 ],\n",
       "       [0.        ],\n",
       "       [0.64814815],\n",
       "       [0.96296296],\n",
       "       [0.18518519],\n",
       "       [0.46296296],\n",
       "       [0.31481481],\n",
       "       [0.94444444],\n",
       "       [0.12962963],\n",
       "       [0.14814815],\n",
       "       [0.38888889],\n",
       "       [0.7962963 ],\n",
       "       [0.2037037 ],\n",
       "       [0.46296296],\n",
       "       [0.5       ],\n",
       "       [0.11111111],\n",
       "       [0.2962963 ],\n",
       "       [0.09259259],\n",
       "       [0.24074074],\n",
       "       [0.22222222],\n",
       "       [0.33333333],\n",
       "       [0.31481481],\n",
       "       [0.2962963 ],\n",
       "       [0.22222222],\n",
       "       [0.16666667],\n",
       "       [0.59259259],\n",
       "       [0.18518519],\n",
       "       [0.16666667],\n",
       "       [0.33333333],\n",
       "       [0.16666667],\n",
       "       [0.18518519],\n",
       "       [0.        ],\n",
       "       [0.44444444],\n",
       "       [0.27777778],\n",
       "       [0.5       ],\n",
       "       [0.44444444],\n",
       "       [0.09259259],\n",
       "       [0.16666667],\n",
       "       [0.11111111],\n",
       "       [0.44444444],\n",
       "       [0.11111111],\n",
       "       [0.        ],\n",
       "       [0.24074074],\n",
       "       [0.35185185],\n",
       "       [0.57407407]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=np.reshape(target,(51,1))\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "32672bc0-1ea3-4bc9-a6b6-bbfd813fec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 4)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_merged,target,test_size=0.2,random_state=42)\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6aace023-9a6c-4152-a4db-907936b0a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.delete(x_test,(0),axis=0)\n",
    "y_test=np.delete(y_test,(0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d369eb59-697a-45e2-beaa-23022d8d1bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8627d5e3-20a3-4fc5-b6d7-062e2d8eea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.reshape(x_train,(20,2,4))\n",
    "x_test=np.reshape(x_test,(5,2,4))\n",
    "y_train=np.reshape(y_train,(20,2))\n",
    "y_test=np.reshape(y_test,(5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "04c862e9-7805-49a2-b03a-008962ff2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0422\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0421\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0420\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0419\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0337 - val_loss: 0.0418\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0417\n"
     ]
    }
   ],
   "source": [
    "y_train.shape\n",
    "model_train=model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d9193922-0ec6-47e5-aa69-679d0954eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 128)               68096     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78977 (308.50 KB)\n",
      "Trainable params: 78977 (308.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "de0c6351-3fb5-4d08-b88b-505a980965c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle  # For permutation importance\n",
    "from tensorflow.keras.models import Model  # Assuming you use TensorFlow/Keras\n",
    "\n",
    "# Load your pre-trained LSTM model (replace 'sequential_3' with your model name)\n",
    "model = Model(inputs=model.input, outputs=model.output)\n",
    "\n",
    "# Function to calculate permutation importance for a feature\n",
    "def permutation_importance(feature_index, X, y, model):\n",
    "  # Copy the data\n",
    "  data = X.copy()\n",
    "  # Shuffle the chosen feature for all data points\n",
    "  data[:, 1] = shuffle(data[:, 1])\n",
    "  # Predict with shuffled data\n",
    "  y_pred_shuffled = model.predict(data)\n",
    "  # Calculate performance difference (e.g., mean squared error difference)\n",
    "  performance_difference = np.mean((y - y_pred_shuffled)**2) - np.mean((y - model.predict(X))**2)\n",
    "  return performance_difference\n",
    "\n",
    "# Feature names\n",
    "feature_names = [\"BrandA_positive\", \"BrandA_negative\", \"BrandB_positive\", \"BrandB_negative\"]\n",
    "\n",
    "# Calculate permutation importance for each feature\n",
    "importance = []\n",
    "for i in range(len(feature_names)):\n",
    "  importance.append(permutation_importance(i, x_train, y_train, model))\n",
    "\n",
    "# Visualize feature importance (bar chart)\n",
    "plt.bar(feature_names, importance)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.title(\"Feature Importance for Brand A Sentiment Prediction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9cf67-f018-4684-ba0f-e3cac5dfe14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
